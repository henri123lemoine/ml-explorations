{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vision Transformer with Spectrogram and Shapley Value Analysis\n",
    "\n",
    "A modular implementation for training ViT models on spectrogram data with Shapley value interpretation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "from vit_pytorch import SimpleViT\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import numpy as np\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelConfig:\n",
    "    \"\"\"Configuration for the ViT model and training parameters.\"\"\"\n",
    "\n",
    "    image_size: tuple[int, int]\n",
    "    patch_size: int\n",
    "    num_classes: int\n",
    "    dim: int\n",
    "    depth: int\n",
    "    heads: int\n",
    "    mlp_dim: int\n",
    "    channels: int\n",
    "    dim_head: int\n",
    "    learning_rate: float = 1e-4\n",
    "    batch_size: int = 32\n",
    "    max_epochs: int = 100\n",
    "    train_split: float = 0.8\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SpectrogramConfig:\n",
    "    \"\"\"Configuration for spectrogram transformation.\"\"\"\n",
    "\n",
    "    n_fft: int = 4\n",
    "    win_length: int | None = None\n",
    "    hop_length: int | None = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputFunction(nn.Module):\n",
    "    \"\"\"Output function with sigmoid activation and rounding.\"\"\"\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.round(torch.sigmoid(x))\n",
    "\n",
    "\n",
    "class SpectrogramTransform(nn.Module):\n",
    "    \"\"\"Spectrogram transformation module.\"\"\"\n",
    "\n",
    "    def __init__(self, config: SpectrogramConfig):\n",
    "        super().__init__()\n",
    "        self.transform = torchaudio.transforms.Spectrogram(\n",
    "            n_fft=config.n_fft, win_length=config.win_length, hop_length=config.hop_length\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.transform(x)\n",
    "\n",
    "\n",
    "class VisionTransformerModel(nn.Module):\n",
    "    \"\"\"Combined ViT model with spectrogram transformation.\"\"\"\n",
    "\n",
    "    def __init__(self, model_config: ModelConfig, spec_config: SpectrogramConfig):\n",
    "        super().__init__()\n",
    "        self.spectrogram = SpectrogramTransform(spec_config)\n",
    "        self.vit = SimpleViT(\n",
    "            image_size=model_config.image_size,\n",
    "            patch_size=model_config.patch_size,\n",
    "            num_classes=model_config.num_classes,\n",
    "            dim=model_config.dim,\n",
    "            depth=model_config.depth,\n",
    "            heads=model_config.heads,\n",
    "            mlp_dim=model_config.mlp_dim,\n",
    "            channels=model_config.channels,\n",
    "            dim_head=model_config.dim_head,\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.spectrogram(x)\n",
    "        x = self.vit(x)\n",
    "        return torch.squeeze(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapleyAnalyzer:\n",
    "    \"\"\"Handles Shapley value computation for feature importance analysis.\"\"\"\n",
    "\n",
    "    def __init__(self, model: nn.Module, device: torch.device):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "\n",
    "    def compute_shapley_values(self, inputs: torch.Tensor, num_samples: int = 100) -> np.ndarray:\n",
    "        \"\"\"Compute Shapley values for each feature using Monte Carlo sampling.\"\"\"\n",
    "        n_features = inputs.shape[1]\n",
    "        shapley_values = np.zeros(n_features)\n",
    "\n",
    "        def model_prediction(subset_indices: list[int]) -> float:\n",
    "            subset_data = inputs.clone()\n",
    "            mask = torch.ones(n_features, dtype=bool)\n",
    "            mask[subset_indices] = False\n",
    "            subset_data[:, mask] = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = self.model(subset_data)\n",
    "                return torch.sigmoid(output).mean().item()\n",
    "\n",
    "        for i in range(n_features):\n",
    "            contributions = []\n",
    "            for _ in range(num_samples):\n",
    "                subset_size = np.random.randint(0, n_features)\n",
    "                subset = np.random.choice(\n",
    "                    [j for j in range(n_features) if j != i], size=subset_size, replace=False\n",
    "                )\n",
    "\n",
    "                with_i = model_prediction(list(subset) + [i])\n",
    "                without_i = model_prediction(list(subset))\n",
    "\n",
    "                weight = (\n",
    "                    np.math.factorial(subset_size)\n",
    "                    * np.math.factorial(n_features - subset_size - 1)\n",
    "                    / np.math.factorial(n_features)\n",
    "                )\n",
    "\n",
    "                contributions.append((with_i - without_i) * weight)\n",
    "\n",
    "            shapley_values[i] = np.mean(contributions)\n",
    "\n",
    "        return shapley_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentManager:\n",
    "    \"\"\"Manages the training process and experiment tracking.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_config: ModelConfig,\n",
    "        spec_config: SpectrogramConfig,\n",
    "        experiment_dir: Path | None = None,\n",
    "    ):\n",
    "        self.model_config = model_config\n",
    "        self.spec_config = spec_config\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.experiment_dir = experiment_dir or Path(f\"data/{datetime.now():%Y%m%d_%H%M%S}\")\n",
    "        self.experiment_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        self.model = VisionTransformerModel(model_config, spec_config).to(self.device)\n",
    "        self.output_fn = OutputFunction().to(self.device)\n",
    "        self.criterion = nn.BCEWithLogitsLoss().to(self.device)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=model_config.learning_rate)\n",
    "\n",
    "    def load_data(self, data_path: Path) -> tuple[DataLoader, DataLoader]:\n",
    "        \"\"\"Load and prepare data for training.\"\"\"\n",
    "        with open(data_path) as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        inputs = torch.tensor(data[\"respMatrix\"]).to(self.device)\n",
    "        targets = torch.tensor(data[\"Y\"]).to(self.device)\n",
    "\n",
    "        # Reshape inputs if necessary\n",
    "        if len(inputs.shape) == 4:  # [n_samples, dim0, dim1, frames]\n",
    "            n_samples, dim0, dim1, frames = inputs.shape\n",
    "            inputs = inputs.view(n_samples, dim0 * dim1, frames)\n",
    "\n",
    "        dataset = TensorDataset(inputs, targets)\n",
    "        train_size = int(self.model_config.train_split * len(dataset))\n",
    "        val_size = len(dataset) - train_size\n",
    "\n",
    "        train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "        return (\n",
    "            DataLoader(train_dataset, batch_size=self.model_config.batch_size, shuffle=True),\n",
    "            DataLoader(val_dataset, batch_size=self.model_config.batch_size),\n",
    "        )\n",
    "\n",
    "    def train_epoch(self, train_loader: DataLoader) -> dict[str, float]:\n",
    "        \"\"\"Train for one epoch.\"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        outputs, targets = [], []\n",
    "\n",
    "        for data, target in train_loader:\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(data)\n",
    "            loss = self.criterion(output, target.float())\n",
    "\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            outputs.extend(self.output_fn(output).cpu().numpy())\n",
    "            targets.extend(target.cpu().numpy())\n",
    "\n",
    "        metrics = {\n",
    "            \"loss\": total_loss / len(train_loader),\n",
    "            \"accuracy\": accuracy_score(targets, outputs),\n",
    "            \"auroc\": roc_auc_score(targets, outputs),\n",
    "        }\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def validate(self, val_loader: DataLoader) -> dict[str, float]:\n",
    "        \"\"\"Perform validation.\"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        outputs, targets = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                output = self.model(data)\n",
    "                loss = self.criterion(output, target.float())\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                outputs.extend(self.output_fn(output).cpu().numpy())\n",
    "                targets.extend(target.cpu().numpy())\n",
    "\n",
    "        metrics = {\n",
    "            \"loss\": total_loss / len(val_loader),\n",
    "            \"accuracy\": accuracy_score(targets, outputs),\n",
    "            \"auroc\": roc_auc_score(targets, outputs),\n",
    "        }\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def run_experiment(self, data_path: Path) -> None:\n",
    "        \"\"\"Run the complete experiment.\"\"\"\n",
    "        logger.info(f\"Starting experiment in {self.experiment_dir}\")\n",
    "        train_loader, val_loader = self.load_data(data_path)\n",
    "\n",
    "        metrics_path = self.experiment_dir / \"metrics.csv\"\n",
    "        with open(metrics_path, \"w\") as f:\n",
    "            f.write(\"epoch,train_loss,train_acc,train_auroc,val_loss,val_acc,val_auroc\\n\")\n",
    "\n",
    "        best_val_accuracy = 0\n",
    "        for epoch in range(self.model_config.max_epochs):\n",
    "            train_metrics = self.train_epoch(train_loader)\n",
    "            val_metrics = self.validate(val_loader)\n",
    "\n",
    "            # Log metrics\n",
    "            with open(metrics_path, \"a\") as f:\n",
    "                f.write(\n",
    "                    f\"{epoch},{train_metrics['loss']:.4f},{train_metrics['accuracy']:.4f},\"\n",
    "                    f\"{train_metrics['auroc']:.4f},{val_metrics['loss']:.4f},\"\n",
    "                    f\"{val_metrics['accuracy']:.4f},{val_metrics['auroc']:.4f}\\n\"\n",
    "                )\n",
    "\n",
    "            # Save best model\n",
    "            if val_metrics[\"accuracy\"] > best_val_accuracy:\n",
    "                best_val_accuracy = val_metrics[\"accuracy\"]\n",
    "                torch.save(self.model.state_dict(), self.experiment_dir / \"best_model.pt\")\n",
    "\n",
    "            logger.info(\n",
    "                f\"Epoch {epoch}: Train Acc={train_metrics['accuracy']:.4f}, \"\n",
    "                f\"Val Acc={val_metrics['accuracy']:.4f}\"\n",
    "            )\n",
    "\n",
    "            # Early stopping check\n",
    "            if val_metrics[\"accuracy\"] == 1.0 or train_metrics[\"accuracy\"] == 1.0:\n",
    "                logger.info(\"Early stopping triggered\")\n",
    "                break\n",
    "\n",
    "        # Compute Shapley values\n",
    "        logger.info(\"Computing Shapley values...\")\n",
    "        analyzer = ShapleyAnalyzer(self.model, self.device)\n",
    "        inputs = train_loader.dataset.tensors[0]\n",
    "        shapley_values = analyzer.compute_shapley_values(inputs)\n",
    "        np.save(self.experiment_dir / \"shapley_values.npy\", shapley_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Example usage of the experiment framework.\"\"\"\n",
    "model_config = ModelConfig(\n",
    "    image_size=(3, 16),  # to adjust based on spectrogram output\n",
    "    patch_size=1,\n",
    "    num_classes=1,\n",
    "    dim=1024,\n",
    "    depth=2,\n",
    "    heads=16,\n",
    "    mlp_dim=2048,\n",
    "    channels=1720,  # to adjust based on input size\n",
    "    dim_head=64,\n",
    ")\n",
    "\n",
    "spec_config = SpectrogramConfig(n_fft=4, win_length=None, hop_length=None)\n",
    "\n",
    "data_path = Path(\"data/prelick_data_no_zeros1.csv\")\n",
    "experiment = ExperimentManager(model_config, spec_config)\n",
    "# experiment.run_experiment(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

experiments_info:
  "1":
    hidden_layers: [128]
    activation_function: ReLU
    initializers: [Zeros, Uniform, Gaussian, Xavier, Kaiming]
    log_scale: [True, False]
  "2":
    hidden_layerss:
      "No Hidden Layers": []
      "One Hidden Layer": [128]
      "Two Hidden Layers": [128, 128]
    activation_function: ReLU
  "3":
    hidden_layers: [128, 128]
    activation_functions: [LeakyReLU, Sigmoid, ReLU]
  "4":
    hidden_layers: [128, 128]
    activation_function: ReLU
    regularizers: [L1, L2, None_]
  "5":
    hidden_layers: [128, 128]
    activation_function: ReLU
    normalizes: [True, False]
  "6":
    normalize: True
    flatten: False
    # activation_function: nn.ReLU
    # optimizer: optim.Adam
    # regularizer: None
    # loss_function: nn.CrossEntropyLoss
    # initializer: Kaiming
  "7":
    input_dim: 3072
    hidden_layers: [128, 128]
    dataset_name: CIFAR10
  "8":
    momentum_values: [0.0, 0.5, 0.9, 0.99]
    log_scale: [False, False]
    flatten: False
    normalize: True
    dataset_name: CIFAR10
  "9":
    flatten: False
    normalize: True
    CACHE_PARTIAL_RESULTS: True
    REUSE_CACHED_RESULTS: True
    dataset_name: CIFAR10
default_parameters:
  n_epochs: 5
  input_dim: 784
  hidden_layers: [128]
  num_classes: 10
  dataset_name: FashionMNIST
  batch_size: 128
  normalize: True
  flatten: True
  lr: 0.005
  activation_function: ReLU
  optimizer: Adam
  scheduler: CosineAnnealing
  regularizer: None_
  loss_function: CrossEntropy
  initializer: Kaiming
  log_scale: [True, False]
global_parameters:
  SAVE_FILES: True
  SHOW_GRAPHS: False
  PRINT_LOSS: True
  CACHE_PARTIAL_RESULTS: True
  REUSE_CACHED_RESULTS: True
  SEED: 42
output_file: False  # "data/experiments_output.txt"
